{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS5803 NLP\n",
    "### Assignment 1\n",
    "#### Tanmay Garg, Tanmay Goyal, Tanay Yadav\n",
    "#### Roll no: CS20BTECH11063, AI20BTECH11021, AI20BTECH11026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **BLEU Score**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $x$ and $y$ be two sentences we wish to compare. Then, we define the modified N-gram as:\n",
    "\n",
    "$$p_n = \\frac{\\sum\\limits_{n-gram \\in x\\cap y}min(count_x(n-gram) , count_y(n-gram))}{\\sum\\limits_{n-gram \\in x}count_x(n-gram)}$$\n",
    "\n",
    "Here, $y$ is the ground truth and $x$ is the machine translated text. \n",
    "\n",
    "Define the BLEU Score as:\n",
    "\n",
    "$$BLEU = BP \\times exp\\left(\\sum\\limits_{n=1}^N w_n \\log(p_n)\\right)$$\n",
    "where $N = 4$ , $w_n = \\frac{1}{N}$ and BP is the Brevity Penalty, which we set to 1.\n",
    "\n",
    "1. Implement the BLEU score metric and pre-process the text by lower-casing the text and removing all punctuations.\n",
    "\n",
    "2. Use this implementation to find the BLEU score when $x$ = \"The boys were playing happily on the ground\" and $y$ = \"The boys were playing football on the field.\"\n",
    "\n",
    "3. Explain why we take a minimum in the numerator.\n",
    "\n",
    "4. Use the implmentation to find the BLEU score for 5 pairs of sentences and explain the disadvantage of the BLEU score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from math import log, exp  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bleu score for above pair of sentences is:  0.4111336169005197\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    '''\n",
    "    Function to preprocess the text by removing punctuations and converting to lower case\n",
    "    '''\n",
    "    # [^\\w\\s] -> ^ means except , \\w refers to any alphanumeric character and \\s refers to whitespace\n",
    "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "    return text\n",
    "\n",
    "def n_gram_dict(text , n):\n",
    "    '''\n",
    "    Function to create a dictionary consisting of the n-grams and their counts\n",
    "    '''\n",
    "    text_list = text.split(' ')\n",
    "    dict = {}    \n",
    "    # we also check for duplicates\n",
    "    for i in range(n-1 , len(text_list)):\n",
    "        key = tuple(text_list[i-n+1 : i+1])\n",
    "        dict[key] = 1 if key not in dict.keys() else dict[key] + 1        \n",
    "    return dict\n",
    "\n",
    "def modified_ngram_precision(n_gram_dict_x, n_gram_dict_y):\n",
    "    '''\n",
    "    Calculates the modified n-gram precision given the n-gram dictionaries for x and y\n",
    "    '''\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for n_gram in n_gram_dict_x.keys():\n",
    "        denominator += n_gram_dict_x[n_gram]\n",
    "        if n_gram in n_gram_dict_y.keys():\n",
    "            numerator += min(n_gram_dict_x[n_gram], n_gram_dict_y[n_gram])\n",
    "            \n",
    "    return numerator/denominator\n",
    "    \n",
    "def bleu_score(x, y, N = 4):\n",
    "    '''\n",
    "    Function to calculate the BLEU score\n",
    "    '''\n",
    "    # preprocessing the text\n",
    "    x = preprocess_text(x)\n",
    "    y = preprocess_text(y)\n",
    "    \n",
    "    BP = 1\n",
    "    weights = [1/N for i in range(N)] \n",
    "\n",
    "    modified_n_gram_list = []\n",
    "\n",
    "    for i in range(1, N+1):\n",
    "        # creating the n-gram dictionaries\n",
    "        n_gram_dict_x = n_gram_dict(x, i)\n",
    "        n_gram_dict_y = n_gram_dict(y, i)\n",
    "        modified_n_gram_list.append(modified_ngram_precision(n_gram_dict_x , n_gram_dict_y))\n",
    "        \n",
    "    score = 0\n",
    "    for (w , p) in zip(weights , modified_n_gram_list):\n",
    "        try:\n",
    "            score += w * log(p)\n",
    "        except:\n",
    "            # p = 0\n",
    "            return 0\n",
    "    return BP * exp(score)\n",
    "\n",
    "x = \"The boys were playing happily on the ground.\"  \n",
    "y = \"The boys were playing football on the field.\"\n",
    "\n",
    "print(\"The bleu score for above pair of sentences is: \", bleu_score(x, y , 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explain why we take a minimum in the numerator**\n",
    "\n",
    "The modified N-gram precision is calculated by taking the minimum of the count of the n-gram in the machine translated text and the count of the n-gram in the ground truth. This prevents repeating N-grams in either of the sentences from inflating the precision. By taking the <i>min ($count_x$, $count_y$)</i> for each N-gram, the metric focuses on measuring overlap rather than the number of times a particular N-gram is repeated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bleu score for the pair of sentences:\n",
      "\n",
      "The boy went to the store\n",
      "The boy went to the mall\n",
      "Score: 0.7598356856515925\n",
      "          \n",
      "The bleu score for the pair of sentences:\n",
      "\n",
      "The cat is now sleeping\n",
      "The cat is now napping\n",
      "Score: 0.668740304976422\n",
      "          \n",
      "The bleu score for the pair of sentences:\n",
      "\n",
      "The child is going to school to study\n",
      "The kid is going to school to learn\n",
      "Score: 0.5410822690539396\n",
      "          \n",
      "The bleu score for the pair of sentences:\n",
      "\n",
      "The officers have gathered for a meeting\n",
      "The officers have gathered for a conference\n",
      "Score: 0.8091067115702212\n",
      "          \n",
      "The bleu score for the pair of sentences:\n",
      "\n",
      "He scored a goal in the football match\n",
      "He scored a goal in the soccer game\n",
      "Score: 0.6803749333171202\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "# Experimenting with the BLEU score for different sentences\n",
    "\n",
    "sentences = [\n",
    "    (\"The boy went to the store\", \"The boy went to the mall\"),\n",
    "    (\"The cat is now sleeping\", \"The cat is now napping\"),\n",
    "    (\"The child is going to school to study\", \"The kid is going to school to learn\"),\n",
    "    (\"The officers have gathered for a meeting\", \"The officers have gathered for a conference\"),\n",
    "    (\"He scored a goal in the football match\", \"He scored a goal in the soccer game\"), \n",
    "]\n",
    "\n",
    "# Calculating the BLEU score for the above sentences\n",
    "for x, y in sentences:\n",
    "    # pretty print the output for better readability\n",
    "    # print(\"The bleu score for the pair of sentences: \", x, \" and \", y, \" is: \", bleu_score(x, y , 4))\n",
    "    print(f\"\"\"The bleu score for the pair of sentences:\\n\\n{x}\\n{y}\\nScore: {bleu_score(x, y , 4)}\n",
    "          \"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Disadvantages of BLEU Score**\n",
    "\n",
    "1. **Lack of Semantic Understanding**: BLEU score only considers the n-gram precision and does not take into account the semantic meaning of the sentence. A pair of sentences may have different words but convey the same meaning. Also, there is no contextual understanding and no consideration for synonyms.\n",
    "\n",
    "2. **Cannot Evaluate Single Sentences**: BLEU score is designed to work on a large corpus of words and is not suitable for evaluating single sentences.\n",
    "\n",
    "3. **Does Not Consider Order of Words**: BLEU score does not consider the order of words and only focuses on counting the n-grams, so sentences with incorrect word order may still get a high BLEU score.\n",
    "\n",
    "4. **Sensitive to Length**: BLEU score is sensitive to the length of the sentences. Longer sentences are penalized as they have more n-grams and shorter sentences are rewarded."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pycharm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
