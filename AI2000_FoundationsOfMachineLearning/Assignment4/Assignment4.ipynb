{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI2000- Foundations of Machine Learning\n",
    "## Assignment 4\n",
    "### Tanmay Goyal\n",
    "### AI20BTECH11021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q.1 Non Uniform weights in Linear Regresssion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A dataset contains datapoints denoted by $(\\vec{x_n}, t_n), n = 1,2,\\ldots, N$. Each datapoint is associated with a non- negative weighting factor $g_n > 0$. The error function is given by:\n",
    "\n",
    "$E(\\vec{w}) = \\frac{1}{2}\\sum_{n=1}^{N}g_n\\left(t_n - \\vec{w}^T\\phi(\\vec{x_n})\\right)^2$\n",
    "\n",
    "#### where $\\phi(.)$ is any representation of the data.\n",
    "\n",
    "#### a) Find an expression for $\\vec{w}^*$ that minimises the above error function.\n",
    "\n",
    "Answer: \n",
    "We first try to convert everything into matrices.\n",
    "Consider:\n",
    "\n",
    "$Y_{N\\times 1} = \\begin{matrix}\n",
    "t_1\\\\\n",
    "t_2\\\\\n",
    "\\vdots\\\\\n",
    "t_N\n",
    "\\end{matrix}$\n",
    "$G_{N\\times N} = diag(\\sqrt{g_1},  \\sqrt{g_2}, \\ldots , \\sqrt{g_N})$\n",
    "$X_{N\\times 1} = \\begin{matrix}\n",
    "\\phi(\\vec{x_1})\\\\\n",
    "\\phi(\\vec{x_2})\\\\\n",
    "\\vdots\\\\\n",
    "\\phi(\\vec{x_N})\n",
    "\\end{matrix}$\n",
    "\n",
    "\n",
    "Then, the error function becomes:\n",
    "\n",
    "$E(\\vec{w}) = \\frac{1}{2}\\sum_{n=1}^{N}g_n\\left(t_n - \\vec{w}^T\\phi(\\vec{x_n})\\right)^2 = \\frac{1}{2}||GY - GX\\vec{w}||^2_2$\n",
    "\n",
    "where $\\vec{w}$ is the weights vector. The optimal solution $\\vec{w}^*$ is given by:\n",
    "\n",
    "\n",
    "$\\vec{w}^* = \\underset{\\vec{w}}{\\operatorname{argmin}}E(\\vec{w}) = \\underset{\\vec{w}}{\\operatorname{argmin}}\\frac{1}{2}||GY - GX\\vec{w}||^2_2$\n",
    "\n",
    "On simplification, $E(\\vec{w}) = \\frac{1}{2}(GY - GX\\vec{w})^T(GY - GX\\vec{w}) = \\frac{1}{2}(Y^TG^TGY - 2Y^TG^TGX\\vec{w} + \\vec{w}^TX^TG^TGX\\vec{w})$\n",
    "\n",
    "Taking the gradient of $E(\\vec{w})$ wrt $\\vec{w}$ and setting it to zero:\n",
    "\n",
    "$\\nabla_{\\vec{w}} E(\\vec{w}) = 0 \\iff \\frac{1}{2}(-2Y^TG^TGX + \\vec{w}^{*T}X^TG^TGX + \\vec{w}^{*T}X^TG^TGX) = 0$\n",
    "\n",
    "$\\implies \\vec{w}^{*T}X^TG^TGX = Y^TG^TGX$\n",
    "\n",
    "Define $A_{N\\times N} = G^TG = diag(g_1, g_2, \\ldots , g_N)$. Then,\n",
    "\n",
    "$\\implies \\vec{w}^{*T}X^TAX = Y^TAX$\n",
    "\n",
    "$\\implies \\vec{w}^{*T} = Y^TAX(X^TAX)^\\ddagger$ where $M^\\ddagger$ represents the pseudo-inverse of $M$.\n",
    "\n",
    "$\\implies \\vec{w}^* = (X^TAX)^\\ddagger X^TA^TY = (X^TAX)^\\ddagger X^TAY$ since $A^T = A$\n",
    "\n",
    "Thus, the solution is $\\vec{w}^* = (X^TAX)^\\ddagger X^TAY$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Give two alternative interpretations of the above weighted sum-of-squares error function in terms of (i) data-dependent noise variance and (ii) replicated data points.\n",
    "\n",
    "Answer: \n",
    "\n",
    "<u>Data dependent Noise Variance</u>\n",
    "\n",
    "Consider $y'_i = \\vec{w}^T\\phi(\\vec{x_i})$ and $y_i = y_i' + \\epsilon_i =  \\vec{w}^T\\phi(\\vec{x_i}) + \\epsilon_i$ where $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$\n",
    "\n",
    "$\\implies y_i|x_i \\sim \\mathcal{N}(\\vec{w}^T\\phi(x_i), \\sigma^2)$\n",
    "\n",
    "Also, $P(y |\\mu ,\\sigma^2 ) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp\\left(\\frac{-(y-\\mu)^2}{2\\sigma^2}\\right)$\n",
    "\n",
    "Let the parametres $\\theta = [\\vec{x} , \\vec{w} , \\sigma^2]$. We have to maximise the likelyhood of the parametres $\\theta$ to simulate labels $y$, i.e to find \n",
    "\n",
    "$\\underset{\\theta}{\\operatorname{argmax}}L(\\theta|y) = \\underset{\\theta}{\\operatorname{argmax}}P(y |\\theta) = \\underset{\\vec{w} , \\sigma^2}{\\operatorname{argmax}}P(y |\\vec{x},\\vec{w}, \\sigma^2)$\n",
    "\n",
    " Since all the datapoints are i.i.d, we maximise the product of the probabilities. Also, maximising the likelyhood is equivalent to maximising the log likelyhood and thus,\n",
    "\n",
    "$ \\underset{\\vec{w} , \\sigma^2}{\\operatorname{argmax}}\\prod_{i=1}^N P(y_i |\\vec{x_i} , \\vec{w} , \\sigma^2) =  \\underset{\\vec{w} , \\sigma^2}{\\operatorname{argmax}}$ $ln \\prod_{i=1}^N P(y_i |\\vec{x_i} , \\vec{w} , \\sigma^2)$\n",
    "\n",
    "$\\underset{\\theta}{\\operatorname{argmax}}L(\\theta|y) = \\underset{\\vec{w} , \\sigma^2}{\\operatorname{argmax}}$ $ln \\left(\\prod_{i=1}^N \\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp\\left(\\frac{-(y_i-\\vec{w}^T\\phi(\\vec{x_i}))^2}{2\\sigma^2}\\right)\\right)$\n",
    "\n",
    "$\\underset{\\theta}{\\operatorname{argmax}}L(\\theta|y) = \\underset{\\vec{w} , \\sigma^2}{\\operatorname{argmax}} \\left[Nln\\left(\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\right) - \\sum_{i=1}^N\\frac{(y_i-\\vec{w}^T\\phi(\\vec{x_i}))^2}{2\\sigma^2}\\right]$\n",
    "\n",
    "$\\underset{\\theta}{\\operatorname{argmax}}L(\\theta|y) = \\underset{\\vec{w},\\sigma^2 }{\\operatorname{argmin}} \\frac{1}{2\\sigma^2}\\sum_{i=1}^N{(y_i-\\vec{w}^T\\phi(\\vec{x_i}))^2}$\n",
    "\n",
    "Thus, maximising the likelyhood of the parameteres $\\theta$ to obtain the labels $y$ is equivalent to minimising the sum of squares error.\n",
    "\n",
    "<u>Replicated Data points</u>\n",
    "\n",
    "Consider a training point $x_i$ to be repeated $g_i$ times, then we can see the error of the training point $x_i$ will get summed $g_i$ times, resulting in the non uniformly weighted error function given in the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q.2 Bayes optimal Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let there be 5 hypothesis $h_1$ to $h_5$ that can guide a robot F, L or R.\n",
    "| $P(h_i\\|D)$ | $P(F\\|h_i)$ | $P(L\\|h_i)$ | $P(R\\|h_i)$ |\n",
    "|-----------|-----------|-----------|-----------|\n",
    "| 0.4       | 1         | 0         | 0         |\n",
    "| 0.2       | 0         | 1         | 0         |\n",
    "| 0.1       | 0         | 0         | 1         |\n",
    "| 0.1       | 0         | 1         | 0         |\n",
    "| 0.2       | 0         | 1         | 0         |\n",
    "\n",
    "#### Compute the MAP estimate and the Bayes Optimal Estimate.\n",
    "\n",
    "Answer: \n",
    "\n",
    "<u>Bayes Optimal Estimate</u>\n",
    "\n",
    "Let $X$ be a random variable taking the values in $\\{1,2,3\\}$ denoting the direction in which the robot moves.\n",
    "Then,\n",
    "\n",
    "$X = 1 \\implies $ F\n",
    "\n",
    "$X = 2 \\implies$ L\n",
    "\n",
    "$X = 3 \\implies $ R\n",
    "\n",
    "Then, the probability that the robot moves in the direction represented by $X = j$ is given by\n",
    "\n",
    "$\\sum_{i=1}^5 P(X=j|(h_i|D))\\times P(h_i|D)$\n",
    "\n",
    "$P(X=1) = \\sum_{i=1}^5 P(X=1|(h_i|D))P(h_i|D) = 0.4$\n",
    "\n",
    "$P(X=2) = \\sum_{i=1}^5 P(X=2|(h_i|D))P(h_i|D) = 0.2 \\times 1 + 0.1 \\times 1 + 0.2 \\times 1 = 0.5$\n",
    "\n",
    "$P(X = 3) = \\sum_{i=1}^5 P(X=3|(h_i|D))P(h_i|D) = 0.1\\times 1 = 0.1$\n",
    "\n",
    "Since, $P(X = 2)$ is the highest, the direction suggested by the Bayes Optimal Estimate is LEFT direction.\n",
    "\n",
    "<u>MAP estimate</u>\n",
    "\n",
    "For the MAP estimate, we find ${\\operatorname{argmax}}P(h_i|D)$\n",
    "\n",
    "Clearly, the maximum of $P((h_i|D))$ is obtained when $h_i = h_1$. When $h_1$ is selected, the only direction the robot can move is in forward direction. Thus, from the MAP estimate, we obtain the most probable direction of the robot to be Forward.\n",
    "\n",
    "Thus, the MAP estimate and the Bayes Optimal Estimate are not the same.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q.3 VC- Dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider a data set up of data $\\in \\mathbb{R}$ where the hypothesis space $\\mathcal{H}$ is parametrised by $\\{p,q\\}$ where $x$ is classified as $1$ iff $p<x<q$. Find the VC dimension of $\\mathcal{H}$\n",
    "\n",
    "Answer: \n",
    "Consider $\\mathcal{H}$ to be the set of hypothesis given by:\n",
    "\n",
    "$\\mathcal{H} = \\{h_1(x,p_1,q_1), h_2(x,p_2,q_2) , \\ldots\\}$\n",
    "\n",
    "where $h_i(x,p_i,q_i) = \\begin{cases}\n",
    "1 & p_i < x < q_i\\\\\n",
    "0 & otherwise\n",
    "\\end{cases}$\n",
    "\n",
    "We consider all possible cases of 2 datapoints $x_1$ and $x_2$, and let $x_1 < x_2$, which can be assumed because both $x_1$ and $x_2$ are scalars, i.e $x_1 , x_2 \\in \\mathbb{R}$. The $2^2$ labellings of these 2 points can be realised by each of the hypothesis as:\n",
    "\n",
    "$x_1 = 0 ; x_2 = 0 \\implies x_1 < x_2 < p < q$\n",
    "\n",
    "$x_1 = 0 ; x_2 = 1 \\implies x_1 < p < x_2 < q$\n",
    "\n",
    "$x_1 = 1 ; x_2 = 1 \\implies p < x_1 < x_2 < q$\n",
    "\n",
    "$x_1 = 1 ; x_2 = 0 \\implies p < x_1 < q < x_2$\n",
    "\n",
    "Thus, by finding suitable $p$ and $q$, any combination of 2 points can be shattered by $\\mathcal{H}$.\n",
    "\n",
    "Consider the case of 3 points, $x_1$, $x_2$ and $x_3$, such that $x_1 < x_2 < x_3$. Consider the labellings of $x_1 = 1 ; x_2 = 0; x_3 = 1$.\n",
    "\n",
    "$x_1 = 1; x_2 = 0 \\implies p < x_1 < q < x_2$\n",
    "\n",
    "Now, since $x_2 < x_3$, this automatically implies $x_3 > q$, and thus $x_3 = 0$. But, the original labelling of $x_3$ was 1, and thus, this combination of labellings cannot be shattered by $\\mathcal{H}$.\n",
    "\n",
    "Since, there is a combination of 3 points that cannot be shattered by $\\mathcal{H}$, the VC- dimension of $\\mathcal{H}$ is $2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Regulariser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given $D$ dimensional data $\\vec{x} = [x_1, x_2 , \\ldots , x_D]$, consider a linear model of the form:\n",
    "\n",
    "$y(\\vec{x},\\vec{w}) = w_0 + \\sum_{k=1}^Dw_kx_k$\n",
    "\n",
    "#### Now, for $N$ such data samples with their corresponding labels $(\\vec{x}_i , t_i)$, the sum of squared error(or mean squared error) is given by:\n",
    "\n",
    "$E(\\vec{w}) = \\frac{1}{2}\\sum_{i=1}^N\\left(y(\\vec{x}_i , \\vec{w})-t_i)\\right)^2$\n",
    "\n",
    "#### Now, suppose Gaussian noise $\\epsilon_k \\sim \\mathcal{N}(0 , \\sigma^2)$ is added independently to each of the input variables $x_k$. Find a relation between minimising the sum of squares error averaged over the noisy data, and minimising the standard sum-of-squares error averaged over noise free data with a $\\mathcal{L}_2$ weight decay regularisation term, in which the bias parameter $w_0$ is omitted from the regulariser.\n",
    "\n",
    "Answer: \n",
    "\n",
    "Let $\\vec{\\epsilon}$ be a vector with $D$ components, which gets added to $\\vec{x}_k$ as noise. Each of the vector $\\vec{\\epsilon}$ are independently picked from $\\mathcal{N}(0 , \\sigma^2)$, and thus:\n",
    "\n",
    "mean = $\\mathbb{E}[\\vec{\\epsilon}] = 0$ \n",
    "\n",
    "covariance = $\\mathbb{E}[\\vec{\\epsilon}\\vec{\\epsilon}^T] = \\sigma^2I_N$\n",
    "\n",
    "Let us define the vector $\\vec{w} = [w_1 , w_2 \\ldots , w_D]^T$\n",
    "\n",
    "The new predicted output $y_{noisy}(\\vec{x},\\vec{w})$ is given by:\n",
    "\n",
    "$y_{noisy}(\\vec{x},\\vec{w}) = w_0 + \\vec{w}^T(\\vec{x}+ \\vec{\\epsilon})$\n",
    "\n",
    "Thus, the expected sum of squared errors averaged over noisy data now becomes:\n",
    "\n",
    "$\\mathbb{E}_\\epsilon[E(\\vec{w})] = \\mathbb{E}_\\epsilon\\left[\\frac{1}{2N}\\sum_{i=1}^N\\left(y_{noisy}(\\vec{x}_i , \\vec{w})-t_i)\\right)^2\\right]$\n",
    "\n",
    "$\\mathbb{E}_\\epsilon[E(\\vec{w})] = \\mathbb{E}_\\epsilon\\left[\\frac{1}{2N}\\sum_{i=1}^N\\left(w_0 + \\vec{w}^T(\\vec{x}_i+ \\vec{\\epsilon}_i)-t_i)\\right)^2\\right]$\n",
    "\n",
    "$\\mathbb{E}_\\epsilon[E(\\vec{w})] = \\mathbb{E}_\\epsilon\\left[\\frac{1}{2N}\\sum_{i=1}^N(w_0 + \\vec{w}^T\\vec{x}_i - t_i) + \\vec{w}^T\\vec{\\epsilon}_i)^2\\right]$\n",
    "\n",
    "$\\mathbb{E}_\\epsilon[E(\\vec{w})] = \\mathbb{E}_\\epsilon\\left[\\frac{1}{2N} \\sum_{i=1}^N(w_0 + \\vec{w}^T\\vec{x}_i - t_i)^2 + (\\vec{w}^T\\vec{\\epsilon}_i)^2 + 2\\vec{w}^T\\vec{\\epsilon}_i(w_0 + \\vec{w}^T\\vec{x}_i - t_i)\\right]$\n",
    "\n",
    "Using linearity of expectation, this now becomes:\n",
    "\n",
    "$\\mathbb{E}_\\epsilon[E(\\vec{w})] = \\frac{1}{2N} \\left[\\mathbb{E}_\\epsilon[\\sum_{i=1}^N(w_0 + \\vec{w}^T\\vec{x}_i - t_i)^2] + \\mathbb{E}_\\epsilon[(\\vec{w}^T\\vec{\\epsilon}_i)^2] + \\mathbb{E}_\\epsilon[2\\vec{w}^T\\vec{\\epsilon}_i(w_0 + \\vec{w}^T\\vec{x}_i - t_i)]\\right]$\n",
    "\n",
    "$\\mathbb{E}_\\epsilon[E(\\vec{w})] = \\frac{1}{2N} \\sum_{i=1}^N(w_0 + \\vec{w}^T\\vec{x}_i - t_i)^2 + \\frac{||\\vec{w}||^2_2}{2N}\\sum_{i=1}^N\\mathbb{E}[\\vec{\\epsilon_i}\\vec{\\epsilon_i}^T] + \\frac{1}{N}(w_0 + \\vec{w}^T\\vec{x}_i - t_i)\\sum_{i=1}^N\\vec{w}^T \\mathbb{E}_\\epsilon[\\vec{\\epsilon}_i]$\n",
    "\n",
    "$\\mathbb{E}_\\epsilon[E(\\vec{w})] = \\frac{1}{2N} \\sum_{i=1}^N(w_0 + \\vec{w}^T\\vec{x}_i - t_i)^2 + \\frac{||\\vec{w}||^2_2}{2N}N\\sigma^2 +0$\n",
    "\n",
    "$\\mathbb{E}_\\epsilon[E(\\vec{w})] = \\frac{1}{2N} \\sum_{i=1}^N(w_0 + \\vec{w}^T\\vec{x}_i - t_i)^2 + \\frac{\\sigma^2}{2}||\\vec{w}||^2_2$\n",
    "\n",
    "Now, the sum of squares error of the noise free data with $\\mathcal{L}_2$ norm regualriser is given by:\n",
    "\n",
    "$E(\\vec{w}) = \\frac{1}{2N}\\sum_{i=1}^N (y(\\vec{x}_i , \\vec{w})-t_i)^2 + \\lambda ||\\vec{w}||^2_2 $\n",
    "\n",
    "$E(\\vec{w}) = \\frac{1}{2N}\\sum_{i=1}^N (w_0 + \\vec{w}^T\\vec{x}_i - t_i)^2 + \\lambda ||\\vec{w}||^2_2 $\n",
    "\n",
    "On comparing, we can see that by making the substitution $\\lambda = \\frac{\\sigma^2}{2}$, both the error functions become the same.\n",
    "\n",
    "Thus, adding noise and adding a regulariser would have the same effect on the problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import math\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part (a)- Implementing code for Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regressor \n",
    "\n",
    "def train_logistic_regressor(X, y, w , lr):\n",
    "\n",
    "    # append a column of 1s along with X to account for bias\n",
    "    X = np.hstack((np.ones((X.shape[0],1)), X))\n",
    "    \n",
    "    # calculating linear model values\n",
    "    f_theta = X @ w\n",
    "    \n",
    "    # inserting linear model values into logistic function\n",
    "    probs = 1 / (1 + np.exp(-f_theta)).reshape((X.shape[0],1))\n",
    "    \n",
    "    # calculating the gradients\n",
    "    gradients = (y-probs).T @ X\n",
    "    gradients = gradients.T\n",
    "\n",
    "    \n",
    "    # calulating new weights\n",
    "    w += lr * gradients\n",
    "\n",
    "    # calculating error\n",
    "    error = 0\n",
    "    for j in range(len(y)):\n",
    "        if y[j]==0:\n",
    "            error += math.log(1 - probs[j])\n",
    "        else:\n",
    "            error += math.log(probs[j])\n",
    "    error *= -1\n",
    "    \n",
    "    return probs , w, error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_logistic_regressor(X,y,w):\n",
    "    # append a column of 1s along with X to account for bias\n",
    "    X = np.hstack((np.ones((X.shape[0],1)), X))\n",
    "\n",
    "    # calculating linear model values\n",
    "    f_theta = X @ w\n",
    "    \n",
    "    # inserting linear model values into logistic function\n",
    "    probs = 1 / (1 + np.exp(-f_theta)).reshape((X.shape[0],1))\n",
    " \n",
    "    # making the predictions in y_hat\n",
    "    y_hat = []\n",
    "    for j in range(len(probs)):\n",
    "        if probs[j] >=0.5:\n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            y_hat.append(0)\n",
    "    y_hat = np.array(y_hat)\n",
    " \n",
    "    # calculating the accuracy\n",
    "    accuracy = 0\n",
    "    for j in range(len(y)):\n",
    "        if(y[j]==y_hat[j]):\n",
    "            accuracy+=1\n",
    "    accuracy /= len(y)\n",
    "    accuracy *= 100\n",
    "\n",
    "    # calculating the precision and recall\n",
    "    TP = FP = TN = FN = 0\n",
    "    for j in range(len(y)):\n",
    "        if y[j]==1 and y_hat[j]==1:\n",
    "            TP+=1\n",
    "        elif y[j]==0 and y_hat[j]==1:\n",
    "            FP+=1\n",
    "        elif y[j]==1 and y_hat[j]==0:\n",
    "            FN+=1\n",
    "        else:\n",
    "            TN +=1\n",
    "    \n",
    "    precision = TP/(TP + FP)\n",
    "    precision *= 100\n",
    "\n",
    "    recall = TP/(TP + FN)\n",
    "    recall *= 100\n",
    "\n",
    "    \n",
    "    return  accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Consider the training and testing sets. We use the linear model $f_\\theta(x_1,x_2) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2$, and the logistic regression function $\\sigma(f_\\theta(x_1 , x_2)) = \\frac{1}{1 + e^{-f_\\theta(x_1 , x_2)}}$. Consider initial weights $\\theta_0 = -1 ,  \\theta_1 = 1.5, \\theta_2 = 0.5$ and learning rate = $0.1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) What is the logistic model $P(\\hat{y}=1|x_1,x_2)$ and the cross entropy function?\n",
    "\n",
    "Answer: \n",
    "\n",
    "$P(\\hat{y}=1|x_1,x_2)$ will be given by:\n",
    "\n",
    "$P(\\hat{y}=1|x_1,x_2) = \\sigma(f_\\theta(x_1 , x_2)) = \\frac{1}{1 + e^{-f_\\theta(x_1 , x_2)}}$\n",
    "\n",
    "$\\implies f_\\theta(x_1,x_2) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 = ln\\left(\\frac{P(\\hat{y}=1|x_1,x_2)}{1-P(\\hat{y}=1|x_1,x_2)}\\right)$\n",
    "\n",
    "The cross entropy funtion $E$ will be given by:\n",
    "\n",
    "$E = -\\left[\\sum_{i=1}^N y_i(P(\\hat{y}=1|x_1,x_2)) + (1-y_i)(P(\\hat{y}=0|x_1,x_2)\\right]$\n",
    "\n",
    "$\\implies E = -\\left[\\sum_{i=1}^N y_i(P(\\hat{y}=1|x_1,x_2)) + (1-y_i)(1 -P(\\hat{y}=1|x_1,x_2) )\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Use gradient descent to update $\\theta_0 , \\theta_1 ,\\theta_2$ for one iteration. Write down the updated logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************************\n",
      "New model parametres are: \n",
      "theta_0 =  -1.0189975586353857\n",
      "theta_1 =  1.5321051772436016\n",
      "theta_2 =  0.5118120174982301\n",
      "***************************************************************************\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([0.346,0.780, 0.303 , 0.439 , 0.358 , 0.729 , 0.602 , 0.863 , 0.790 , 0.753 , 0.611 , 0.965]).reshape((6,2))\n",
    "y_train = np.array([0,0,0,1,1,1]).reshape((6,1))\n",
    "weights = np.array([-1,1.5,0.5]).reshape((3,1))\n",
    "lr = 0.1\n",
    "\n",
    "probs, weights, error = train_logistic_regressor(X_train, y_train, weights, lr)\n",
    "\n",
    "\n",
    "\n",
    "print(\"*\"*75)\n",
    "print(\"New model parametres are: \")\n",
    "print(\"theta_0 = \", weights[0][0])\n",
    "print(\"theta_1 = \", weights[1][0])\n",
    "print(\"theta_2 = \", weights[2][0])\n",
    "print(\"*\"*75)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) At the convergence of gradient descent, make predictions on the test dataset, and report the accuracy, precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converging gradient descent till the error does not decrease\n",
    "\n",
    "# let error2 be the error of the nth epoch and error 1 be the error of the (n-1)th epoch\n",
    "#error1 = 0\n",
    "#error2 = error\n",
    "#while(error2-error1 < 0.00005):\n",
    "while(error>0.01):\n",
    "    probs , weights , error = train_logistic_regressor(X_train, y_train , weights, lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************************\n",
      "accuracy =  66.66666666666666\n",
      "precision =  60.0\n",
      "recall =  100.0\n",
      "***************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# testing on dataset\n",
    "X_test = np.array([0.959,0.382,0.750,0.306,0.395,0.760,0.823,0.764,0.761,0.874,0.844,0.435]).reshape((6,2))\n",
    "y_test = np.array([0,0,0,1,1,1]).reshape((6,1))\n",
    "\n",
    "acc, prec , recall = test_logistic_regressor(X_test, y_test, weights)\n",
    "\n",
    "\n",
    "print(\"*\"*75)\n",
    "print(\"accuracy = \", acc)\n",
    "print(\"precision = \",prec)\n",
    "print(\"recall = \", recall)\n",
    "print(\"*\"*75)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q.6 Kaggle- Taxi Fare Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9914, 7)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading testing data\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-06-15 17:26:21.0000001</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-06-15 17:26:21 UTC</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05 16:52:16.0000002</td>\n",
       "      <td>16.9</td>\n",
       "      <td>2010-01-05 16:52:16 UTC</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-18 00:35:00.00000049</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2011-08-18 00:35:00 UTC</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-21 04:30:42.0000001</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2012-04-21 04:30:42 UTC</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-09 07:51:00.000000135</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2010-03-09 07:51:00 UTC</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             key  fare_amount          pickup_datetime  \\\n",
       "0    2009-06-15 17:26:21.0000001          4.5  2009-06-15 17:26:21 UTC   \n",
       "1    2010-01-05 16:52:16.0000002         16.9  2010-01-05 16:52:16 UTC   \n",
       "2   2011-08-18 00:35:00.00000049          5.7  2011-08-18 00:35:00 UTC   \n",
       "3    2012-04-21 04:30:42.0000001          7.7  2012-04-21 04:30:42 UTC   \n",
       "4  2010-03-09 07:51:00.000000135          5.3  2010-03-09 07:51:00 UTC   \n",
       "\n",
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.844311        40.721319         -73.841610         40.712278   \n",
       "1        -74.016048        40.711303         -73.979268         40.782004   \n",
       "2        -73.982738        40.761270         -73.991242         40.750562   \n",
       "3        -73.987130        40.733143         -73.991567         40.758092   \n",
       "4        -73.968095        40.768008         -73.956655         40.783762   \n",
       "\n",
       "   passenger_count  \n",
       "0                1  \n",
       "1                1  \n",
       "2                2  \n",
       "3                1  \n",
       "4                1  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# because there are around 10000 rows of testing data, and 55 million rows of training data, \n",
    "# we would use only 1000000 rows of training data\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"train.csv\" , nrows = 1000000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping key column\n",
    "df.drop(['key'], axis = 'columns' , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "      <td>17:26:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.9</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "      <td>16:52:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "      <td>00:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.7</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "      <td>04:30:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "      <td>07:51:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0          4.5        -73.844311        40.721319         -73.841610   \n",
       "1         16.9        -74.016048        40.711303         -73.979268   \n",
       "2          5.7        -73.982738        40.761270         -73.991242   \n",
       "3          7.7        -73.987130        40.733143         -73.991567   \n",
       "4          5.3        -73.968095        40.768008         -73.956655   \n",
       "\n",
       "   dropoff_latitude  passenger_count      time  \n",
       "0         40.712278                1  17:26:21  \n",
       "1         40.782004                1  16:52:16  \n",
       "2         40.750562                2  00:35:00  \n",
       "3         40.758092                1  04:30:42  \n",
       "4         40.783762                1  07:51:00  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting time from pickup_datetime\n",
    "\n",
    "new = df['pickup_datetime'].str.split(\" \" , n=2 , expand = True)\n",
    "df['time'] = new[1]\n",
    "\n",
    "# drop pickup_datetime column\n",
    "df.drop(['pickup_datetime'] , axis = 'columns' , inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.9</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.7</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0          4.5        -73.844311        40.721319         -73.841610   \n",
       "1         16.9        -74.016048        40.711303         -73.979268   \n",
       "2          5.7        -73.982738        40.761270         -73.991242   \n",
       "3          7.7        -73.987130        40.733143         -73.991567   \n",
       "4          5.3        -73.968095        40.768008         -73.956655   \n",
       "\n",
       "   dropoff_latitude  passenger_count hours  \n",
       "0         40.712278                1    17  \n",
       "1         40.782004                1    16  \n",
       "2         40.750562                2    00  \n",
       "3         40.758092                1    04  \n",
       "4         40.783762                1    07  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting the hours column from time\n",
    "new = df['time'].str.split(\":\" , n=2 , expand = True)\n",
    "df['hours'] = new[0]\n",
    "\n",
    "# dropping time column\n",
    "df.drop(['time'] , axis = 'columns' , inplace = True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting hours into binary variable\n",
    "# if the taxi was booked between 20 hrs and 08 hrs then it will be \n",
    "# represented by a column 'night charges'\n",
    "df['hours'].astype(int)\n",
    "night_charge_hrs = [i for i in range(9)] + [20,21,22,23]\n",
    "df['night_charges'] = df.apply(lambda row: 1 if row.hours in night_charge_hrs else 0 , axis = 'columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>night_charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.9</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.7</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0          4.5        -73.844311        40.721319         -73.841610   \n",
       "1         16.9        -74.016048        40.711303         -73.979268   \n",
       "2          5.7        -73.982738        40.761270         -73.991242   \n",
       "3          7.7        -73.987130        40.733143         -73.991567   \n",
       "4          5.3        -73.968095        40.768008         -73.956655   \n",
       "\n",
       "   dropoff_latitude  passenger_count  night_charges  \n",
       "0         40.712278                1              0  \n",
       "1         40.782004                1              0  \n",
       "2         40.750562                2              0  \n",
       "3         40.758092                1              0  \n",
       "4         40.783762                1              0  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['hours'] , axis = 'columns' , inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with negative fare amount\n",
    "df.drop(df[df['fare_amount']<0].index , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>night_charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.5</td>\n",
       "      <td>-73.844311</td>\n",
       "      <td>40.721319</td>\n",
       "      <td>-73.841610</td>\n",
       "      <td>40.712278</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.9</td>\n",
       "      <td>-74.016048</td>\n",
       "      <td>40.711303</td>\n",
       "      <td>-73.979268</td>\n",
       "      <td>40.782004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>-73.982738</td>\n",
       "      <td>40.761270</td>\n",
       "      <td>-73.991242</td>\n",
       "      <td>40.750562</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.7</td>\n",
       "      <td>-73.987130</td>\n",
       "      <td>40.733143</td>\n",
       "      <td>-73.991567</td>\n",
       "      <td>40.758092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.968095</td>\n",
       "      <td>40.768008</td>\n",
       "      <td>-73.956655</td>\n",
       "      <td>40.783762</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0          4.5        -73.844311        40.721319         -73.841610   \n",
       "1         16.9        -74.016048        40.711303         -73.979268   \n",
       "2          5.7        -73.982738        40.761270         -73.991242   \n",
       "3          7.7        -73.987130        40.733143         -73.991567   \n",
       "4          5.3        -73.968095        40.768008         -73.956655   \n",
       "\n",
       "   dropoff_latitude  passenger_count  night_charges  \n",
       "0         40.712278                1              0  \n",
       "1         40.782004                1              0  \n",
       "2         40.750562                2              0  \n",
       "3         40.758092                1              0  \n",
       "4         40.783762                1              0  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making night_charges column for test_data\n",
    "\n",
    "# extracting time from pickup_datetime\n",
    "\n",
    "new = test_df['pickup_datetime'].str.split(\" \" , n=2 , expand = True)\n",
    "test_df['time'] = new[1]\n",
    "\n",
    "# drop pickup_datetime column\n",
    "test_df.drop(['pickup_datetime'] , axis = 'columns' , inplace = True)\n",
    "\n",
    "\n",
    "# extracting the hours column from time\n",
    "new = test_df['time'].str.split(\":\" , n=2 , expand = True)\n",
    "test_df['hours'] = new[0]\n",
    "\n",
    "# dropping time column\n",
    "test_df.drop(['time'] , axis = 'columns' , inplace = True)\n",
    "\n",
    "# converting hours into binary variable\n",
    "# if the taxi was booked between 20 hrs and 08 hrs then it will be \n",
    "# represented by a column 'night charges'\n",
    "test_df['hours'].astype(int)\n",
    "night_charge_hrs = [i for i in range(9)] + [20,21,22,23]\n",
    "test_df['night_charges'] = test_df.apply(lambda row: 1 if row.hours in night_charge_hrs else 0 , axis = 'columns')\n",
    "\n",
    "# dropping hours column\n",
    "test_df.drop(['hours'] , axis = 'columns' , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing the same pre-processing for testing data\n",
    "# keeping the keys column for further use\n",
    "\n",
    "keys = test_df['key']\n",
    "\n",
    "test_df.drop(['key'], axis = 'columns' , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ensure there are no infinite or Nan values\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(axis ='index' , inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>night_charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-73.973320</td>\n",
       "      <td>40.763805</td>\n",
       "      <td>-73.981430</td>\n",
       "      <td>40.743835</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-73.986862</td>\n",
       "      <td>40.719383</td>\n",
       "      <td>-73.998886</td>\n",
       "      <td>40.739201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-73.982524</td>\n",
       "      <td>40.751260</td>\n",
       "      <td>-73.979654</td>\n",
       "      <td>40.746139</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-73.981160</td>\n",
       "      <td>40.767807</td>\n",
       "      <td>-73.990448</td>\n",
       "      <td>40.751635</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-73.966046</td>\n",
       "      <td>40.789775</td>\n",
       "      <td>-73.988565</td>\n",
       "      <td>40.744427</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \\\n",
       "0        -73.973320        40.763805         -73.981430         40.743835   \n",
       "1        -73.986862        40.719383         -73.998886         40.739201   \n",
       "2        -73.982524        40.751260         -73.979654         40.746139   \n",
       "3        -73.981160        40.767807         -73.990448         40.751635   \n",
       "4        -73.966046        40.789775         -73.988565         40.744427   \n",
       "\n",
       "   passenger_count  night_charges  \n",
       "0                1              0  \n",
       "1                1              0  \n",
       "2                1              0  \n",
       "3                1              0  \n",
       "4                1              0  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting our data into np arrays for further processing\n",
    "\n",
    "columns_without_target = [column for column in df.columns if column != 'fare_amount']\n",
    "X_train = np.array(df[columns_without_target])\n",
    "y_train = np.array(df[\"fare_amount\"])\n",
    "X_test = np.array(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Gradient Boosting Regressor: Score = 3.88476"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(n_estimators=500)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the model\n",
    "\n",
    "reg = GradientBoostingRegressor(n_estimators = 500 )\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediciting on test data\n",
    "y_pred = reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-27 13:08:24.0000002</td>\n",
       "      <td>7.544727327018277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-27 13:08:24.0000003</td>\n",
       "      <td>8.04812300768784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-08 11:53:44.0000002</td>\n",
       "      <td>6.5466534063335935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-01 21:12:12.0000002</td>\n",
       "      <td>8.157517999053074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-01 21:12:12.0000003</td>\n",
       "      <td>14.840991576462379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>2015-05-10 12:37:51.0000002</td>\n",
       "      <td>7.7051055273120514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>2015-01-12 17:05:51.0000001</td>\n",
       "      <td>7.332029721889704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>2015-04-19 20:44:15.0000001</td>\n",
       "      <td>47.588115488004114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>2015-01-31 01:05:19.0000005</td>\n",
       "      <td>21.017202310349845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9913</th>\n",
       "      <td>2015-01-18 14:06:23.0000006</td>\n",
       "      <td>7.750538823362611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              key         fare_amount\n",
       "0     2015-01-27 13:08:24.0000002   7.544727327018277\n",
       "1     2015-01-27 13:08:24.0000003    8.04812300768784\n",
       "2     2011-10-08 11:53:44.0000002  6.5466534063335935\n",
       "3     2012-12-01 21:12:12.0000002   8.157517999053074\n",
       "4     2012-12-01 21:12:12.0000003  14.840991576462379\n",
       "...                           ...                 ...\n",
       "9909  2015-05-10 12:37:51.0000002  7.7051055273120514\n",
       "9910  2015-01-12 17:05:51.0000001   7.332029721889704\n",
       "9911  2015-04-19 20:44:15.0000001  47.588115488004114\n",
       "9912  2015-01-31 01:05:19.0000005  21.017202310349845\n",
       "9913  2015-01-18 14:06:23.0000006   7.750538823362611\n",
       "\n",
       "[9914 rows x 2 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the predicitions dataframe for easy convertion to csv\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(keys)):\n",
    "    predictions.append([keys[i] , y_pred[i]])\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "pred_df = pd.DataFrame(predictions , columns = ['key' , 'fare_amount'])\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to csv file\n",
    "pred_df.to_csv('GradientBoostingRegressor.csv' , columns = ['key' , 'fare_amount'] , header = ['key' , 'fare_amount'] , index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Model 2: KNN regressor: Score = 3.89869"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neighbors.KNeighborsRegressor(n_neighbors = 7)\n",
    "model.fit(X_train, y_train)  #fit the model\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-27 13:08:24.0000002</td>\n",
       "      <td>8.585714285714285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-27 13:08:24.0000003</td>\n",
       "      <td>9.885714285714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-08 11:53:44.0000002</td>\n",
       "      <td>5.228571428571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-01 21:12:12.0000002</td>\n",
       "      <td>7.442857142857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-01 21:12:12.0000003</td>\n",
       "      <td>16.271428571428572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9909</th>\n",
       "      <td>2015-05-10 12:37:51.0000002</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9910</th>\n",
       "      <td>2015-01-12 17:05:51.0000001</td>\n",
       "      <td>8.557142857142855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>2015-04-19 20:44:15.0000001</td>\n",
       "      <td>54.208571428571425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>2015-01-31 01:05:19.0000005</td>\n",
       "      <td>14.757142857142858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9913</th>\n",
       "      <td>2015-01-18 14:06:23.0000006</td>\n",
       "      <td>6.514285714285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              key         fare_amount\n",
       "0     2015-01-27 13:08:24.0000002   8.585714285714285\n",
       "1     2015-01-27 13:08:24.0000003   9.885714285714286\n",
       "2     2011-10-08 11:53:44.0000002   5.228571428571429\n",
       "3     2012-12-01 21:12:12.0000002   7.442857142857143\n",
       "4     2012-12-01 21:12:12.0000003  16.271428571428572\n",
       "...                           ...                 ...\n",
       "9909  2015-05-10 12:37:51.0000002                 9.5\n",
       "9910  2015-01-12 17:05:51.0000001   8.557142857142855\n",
       "9911  2015-04-19 20:44:15.0000001  54.208571428571425\n",
       "9912  2015-01-31 01:05:19.0000005  14.757142857142858\n",
       "9913  2015-01-18 14:06:23.0000006   6.514285714285714\n",
       "\n",
       "[9914 rows x 2 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the predicitions dataframe for easy convertion to csv\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(keys)):\n",
    "    predictions.append([keys[i] , y_pred[i]])\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "pred_df = pd.DataFrame(predictions , columns = ['key' , 'fare_amount'])\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to csv file\n",
    "pred_df.to_csv('KNearestNeighboursRegressor.csv' , columns = ['key' , 'fare_amount'] , header = ['key' , 'fare_amount'] , index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report\n",
    "\n",
    "Models that worked: GradientBoosting Regressor (n_estimators = 500), KNN Regressor(k = 7)\n",
    "\n",
    "Other models that were Tried: LinearSVR , GradientBoosting Regressor(n_estimators = 200), RandomForestRegressor\n",
    "\n",
    "<u>Gradient Boosting Regressor(n_estimators = 500)</u>: Score = 3.88476\n",
    "\n",
    "As the number of estimators increase, the performance of the Gradient Boosting regressor improves because it is robust to over fitting. Also, the Gradient Boosting regressor combines various models, each improving on the performance of its predeccesor, which leads to better performance in general.\n",
    "\n",
    "<u>KNN regressor(K = 7)</u>: Score = 3.89869\n",
    "\n",
    "The KNN regressor worked pretty well because of the similar scales of data, and the similarity in the column features. Since the longitudes and latitudes can be used to relate distance on similar scales, the KNN regressor picked it up pretty well, as compared to Random forests, where the precision in longitudes and latitudes can cause some differences.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "484e8679c47fd18b4a8645d24b23a55255c346c499f8d1a07b980b9195f257e7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
